{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer, Input, Dropout, Conv2D, Activation, add, UpSampling2D,     Conv2DTranspose, Flatten, Reshape\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization, InputSpec\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import os\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "from skimage import color\n",
    "from helper_funcs import *\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "\n",
    "# ### Model parameters\n",
    "# \n",
    "# This CycleGAN implementation allows a lot of freedom on both the training parameters and the network architecture.\n",
    "\n",
    "opt = {}\n",
    "\n",
    "# Data\n",
    "opt['channels'] = 1\n",
    "opt['img_shape'] = (256,256,1)\n",
    "\n",
    "# Architecture parameters\n",
    "opt['use_dropout'] = False  # Dropout in residual blocks\n",
    "opt['use_bias'] = True  # Use bias\n",
    "opt['use_resize_convolution'] = True  # Resize convolution - instead of transpose convolution in deconvolution layers (uk) - can reduce checkerboard artifacts but the blurring might affect the cycle-consistency\n",
    "\n",
    "# Tweaks\n",
    "opt['REAL_LABEL'] = 1.0  # Use e.g. 0.9 to avoid training the discriminators to zero loss\n",
    "\n",
    "# ### Model architecture\n",
    "# \n",
    "# #### Layer blocks\n",
    "# These are the individual layer blocks that are used to build the generators and discriminator. More information can be found in the appendix of the [CycleGAN paper](https://arxiv.org/abs/1703.10593).\n",
    "\n",
    "# Discriminator layers\n",
    "def ck(model, opt, x, k, use_normalization, use_bias):\n",
    "    x = Conv2D(filters=k, kernel_size=4, strides=2, padding='same', use_bias=use_bias)(x)\n",
    "    if use_normalization:\n",
    "        x = model['normalization'](axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "# First generator layer\n",
    "def c7Ak(model, opt, x, k):\n",
    "    x = Conv2D(filters=k, kernel_size=7, strides=1, padding='valid', use_bias=opt['use_bias'])(x)\n",
    "    x = model['normalization'](axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Downsampling\n",
    "def dk(model, opt, x, k):  # Should have reflection padding\n",
    "    x = Conv2D(filters=k, kernel_size=3, strides=2, padding='same', use_bias=opt['use_bias'])(x)\n",
    "    x = model['normalization'](axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Residual block\n",
    "def Rk(model, opt, x0):\n",
    "    k = int(x0.shape[-1])\n",
    "\n",
    "    # First layer\n",
    "    x = ReflectionPadding2D((1,1))(x0)\n",
    "    x = Conv2D(filters=k, kernel_size=3, strides=1, padding='valid', use_bias=opt['use_bias'])(x)\n",
    "    x = model['normalization'](axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if opt['use_dropout']:\n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "    # Second layer\n",
    "    x = ReflectionPadding2D((1, 1))(x)\n",
    "    x = Conv2D(filters=k, kernel_size=3, strides=1, padding='valid', use_bias=opt['use_bias'])(x)\n",
    "    x = model['normalization'](axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "    # Merge\n",
    "    x = add([x, x0])\n",
    "\n",
    "    return x\n",
    "\n",
    "# Upsampling\n",
    "def uk(model, opt, x, k):\n",
    "    # (up sampling followed by 1x1 convolution <=> fractional-strided 1/2)\n",
    "    if opt['use_resize_convolution']:\n",
    "        x = UpSampling2D(size=(2, 2))(x)  # Nearest neighbor upsampling\n",
    "        x = ReflectionPadding2D((1, 1))(x)\n",
    "        x = Conv2D(filters=k, kernel_size=3, strides=1, padding='valid', use_bias=opt['use_bias'])(x)\n",
    "    else:\n",
    "        x = Conv2DTranspose(filters=k, kernel_size=3, strides=2, padding='same', use_bias=opt['use_bias'])(x)  # this matches fractionally stided with stride 1/2\n",
    "    x = model['normalization'](axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# #### Architecture functions\n",
    "\n",
    "def build_generator(model, opt, name=None):\n",
    "    # Layer 1: Input\n",
    "\n",
    "    input_img = Input(shape=opt['img_shape'])\n",
    "    x = ReflectionPadding2D((3, 3))(input_img)\n",
    "    x = c7Ak(model, opt, x, 32)\n",
    "\n",
    "    # Layer 2-3: Downsampling\n",
    "    x = dk(model, opt, x, 64)\n",
    "    x = dk(model, opt, x, 128)\n",
    "\n",
    "    # Layers 4-12: Residual blocks\n",
    "    for _ in range(4, 13):\n",
    "        x = Rk(model, opt, x)\n",
    "\n",
    "    # Layer 13:14: Upsampling\n",
    "    x = uk(model, opt, x, 64)\n",
    "    x = uk(model, opt, x, 32)\n",
    "\n",
    "    # Layer 15: Output\n",
    "    x = ReflectionPadding2D((3, 3))(x)\n",
    "    x = Conv2D(opt['channels'], kernel_size=7, strides=1, padding='valid', use_bias=True)(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    # x = Reshape((217,181,1))(x)\n",
    "    # print(\"Generator Model:\")\n",
    "    # print(Model(inputs=input_img, outputs=x, name=name).summary())\n",
    "    return Model(inputs=input_img, outputs=x, name=name)\n",
    "\n",
    "# Load Model\n",
    "\n",
    "model = {}\n",
    "# Normalization\n",
    "model['normalization'] = InstanceNormalization\n",
    "model['G_A2B'] = build_generator(model, opt, name='G_A2B_model')\n",
    "model['G_B2A'] = build_generator(model, opt, name='G_B2A_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b359ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell tests the A2B images. I know this code is not good. If someone can help me optimize this code, I would be grateful.\n",
    "# You need to change the \"weight_path\" and \"save_path\" to your path. And according to your file name change the conditional sentence.\n",
    "\n",
    "GA2B = model['G_A2B']\n",
    "\n",
    "# You need to update the \"weight_path\", \"save_path\", \"dataset_path\" information\n",
    "weight_path = '/data/jiayuan/saved_models'\n",
    "save_path = '/data/jiayuan/SaveTestImage'\n",
    "dataset_path = '/data/jiayuan/dataset/'\n",
    "\n",
    "files_name = os.listdir(weight_path)\n",
    "\n",
    "for name in files_name:\n",
    "    if 'trip-ce-ssimG_rate5True10.0100datasettime' in name: # You need to change this.\n",
    "#         b = name.split('.0')\n",
    "        b = name.split('.0') # Change here\n",
    "        c = b[0].split('True') # Change here\n",
    "        file_name = c[0]+c[1]\n",
    "        a=b[1].split('time') # Change here\n",
    "        weight_file = os.path.join(weight_path,name)\n",
    "        for weight in os.listdir(weight_file):\n",
    "            if 'A2B' in weight and '.hdf5' in weight:\n",
    "                print(os.path.join(weight_file,weight))\n",
    "                GA2B.load_weights(os.path.join(weight_file,weight))\n",
    "                m=weight.split(\"_\")[5]\n",
    "                c=m.split('.')\n",
    "\n",
    "                if not os.path.exists(os.path.join(save_path,file_name,b[1],'a2b',c[0])):\n",
    "                    os.makedirs(os.path.join(save_path,file_name,b[1],'a2b',c[0]))\n",
    "                image_path = dataset_path+a[0]+'/testCT'\n",
    "                image_another = dataset_path+a[0]+'/testMRI'\n",
    "                if a[0]==\"T1-T2\":\n",
    "                    image_path = dataset_path+a[0]+'/TestT1'\n",
    "                    image_another = dataset_path+a[0]+'/TestT2'\n",
    "                for images in os.listdir(image_path):\n",
    "                    image = mpimg.imread(os.path.join(image_path,images))\n",
    "                    image = resize(image,(256,256))\n",
    "                    image = image[:, :, np.newaxis]\n",
    "                    image = image * 2 - 1\n",
    "                    real_image = image\n",
    "                    image = np.reshape(image,(1, 256,256,1))\n",
    "                    real_another = mpimg.imread(os.path.join(image_another,images))\n",
    "                    real_another = resize(real_another,(256,256))\n",
    "                    real_another = real_another[:, :, np.newaxis]\n",
    "                    real_another = real_another * 2 - 1\n",
    "                    im = GA2B.predict(image)\n",
    "                    im = np.reshape(im,(256,256))\n",
    "                    im = im[:, :, np.newaxis]\n",
    "                    save_image_path = os.path.join(save_path,file_name,b[1],'a2b',c[0],images)\n",
    "                    # This is to save the source image, predict image, and target image.\n",
    "                    join_and_save(opt, (real_image, im, real_another), save_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell tests the B2A images. I know this code is not good. If someone can help me optimize this code, I would be grateful.\n",
    "# You need to change the \"weight_path\" and \"save_path\" to your path. And according to your file name change the conditional sentence.\n",
    "\n",
    "\n",
    "GB2A = model['G_B2A']\n",
    "\n",
    "files_name = os.listdir(weight_path)\n",
    "\n",
    "for name in files_name:\n",
    "    if 'trip-ce-ssimG_rate5True10.0100datasettime1' in name: # You need to change this.\n",
    "        b = name.split('.0') # Change here\n",
    "        c = b[0].split('True') # Change here\n",
    "        file_name = c[0]+c[1]\n",
    "        a=b[1].split('time') # Change here\n",
    "        weight_file = os.path.join(weight_path,name)\n",
    "        for weight in os.listdir(weight_file):\n",
    "            if 'B2A' in weight and '.hdf5' in weight:\n",
    "                print(os.path.join(weight_file,weight))\n",
    "                GB2A.load_weights(os.path.join(weight_file,weight))\n",
    "                m=weight.split(\"_\")[5]\n",
    "                c=m.split('.')\n",
    "\n",
    "                if not os.path.exists(os.path.join(save_path,file_name,b[1],'b2a',c[0])):\n",
    "                    os.makedirs(os.path.join(save_path,file_name,b[1],'b2a',c[0]))\n",
    "                image_path = dataset_path+a[0]+'/testMRI'\n",
    "                image_another = dataset_path+a[0]+'/testCT'\n",
    "                if a[0]==\"T1-T2\":\n",
    "                    image_path = dataset_path+a[0]+'/TestT2'\n",
    "                    image_another = dataset_path+a[0]+'/TestT1'\n",
    "                for images in os.listdir(image_path):\n",
    "                    image = mpimg.imread(os.path.join(image_path,images))\n",
    "                    image = resize(image,(256,256))\n",
    "                    image = image[:, :, np.newaxis]\n",
    "                    image = image * 2 - 1\n",
    "                    real_image = image\n",
    "                    image = np.reshape(image,(1, 256,256,1))\n",
    "                    real_another = mpimg.imread(os.path.join(image_another,images))\n",
    "                    real_another = resize(real_another,(256,256))\n",
    "                    real_another = real_another[:, :, np.newaxis]\n",
    "                    real_another = real_another * 2 - 1\n",
    "                    real_another = real_another\n",
    "                    im = GB2A.predict(image)\n",
    "                    im = np.reshape(im,(256,256))\n",
    "                    im = im[:, :, np.newaxis]\n",
    "                    save_image_path = os.path.join(save_path,file_name,b[1],'b2a',c[0],images)\n",
    "                    # This is to save the source image, predict image, and target image.\n",
    "                    join_and_save(opt,(real_image, im, real_another) , save_image_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38292070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MRCT]",
   "language": "python",
   "name": "conda-env-MRCT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
